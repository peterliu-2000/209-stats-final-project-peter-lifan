---
title: "STATS209 Final Project"
format: pdf
editor: visual
---

## Motivation & Outline

**TODO: some background on Kuaishou, video streaming industry etc.**

**TODO: expand: primary motivation:** video streaming platforms like Tiktok and Kuaishou, vertical video format is more natural/native towards how people hold the phones (more often vertically than horizontally while swiping for videos), while for horizontal videos ppl oftentimes have to turn the phone, remove rotation lock if needed to fully engage with the video: some additional hassel. So one empirical observation is that

**TODO: Also discuss how causal analysis with traditional video interaction logs are problematic due to the non-randomized nature of video impressions.**

-   Treatment T: video horizontal (1) vs vertical (0)

-   Outcome Y: whether the user clicks / likes the video

-   Covariates X: other user & video features

Key insights: when `is_rand` = 1, user sees a video randomly chosen from a pool of 7388 video candidates: so technically the randomization is based on video ID, but since each video has a fixed format across all impressions (verified), this means that the treatment assignment is also as good as random

## Data Load

```{r}
library(dplyr)
library(ggplot2)
library(tidyr)
library(cobalt)

random_path = 'data/KuaiRand-1K/data/log_random_4_22_to_5_08_1k.csv'
user_features_path = 'data/KuaiRand-1K/data/user_features_1k.csv'
video_features_path = 'data/KuaiRand-1K/data/video_features_basic_1k.csv'

random = read.csv(random_path)
user_features = read.csv(user_features_path)
video_features = read.csv(video_features_path)
```

## Randomized Trials

```{r}
#Treatment variable creation:
#T = 1 if horizontal, else vertical
video_features$T = as.integer(video_features$server_width > video_features$server_height)
```

```{r}
#merge random logs and user & video features
random_merged <- random %>%
  left_join(video_features, by = "video_id")

random_merged <- random_merged %>%
  left_join(user_features, by = "user_id")

length(unique(random_merged$video_id))
length(unique(random_merged$user_id))
dim(random_merged)

#release storage
rm(random, user_features, video_features)
```

```{r}
#check distributions of treatment and outcome 
table(random_merged$T)
table(random_merged$is_click)
table(random_merged$is_like)
```

Nice: each unique video is guaranteed to have the same height\*width across random impressions (i.e each video ID has a fixed T label)

```{r}
#check the possibility of different aspect ratios of any video at different impressions
video_aspects <- random_merged %>%
  distinct(video_id, server_width, server_height)

aspect_counts <- video_aspects %>%
  count(video_id, name = "n_aspect_combos")

table(aspect_counts$n_aspect_combos)
```

```{r}
#Checking for covariate balance in randomized logs:
#TODO: This might not be necessary??
smd <- function(x, t) {
  m1 <- mean(x[t == 1], na.rm = TRUE)
  m0 <- mean(x[t == 0], na.rm = TRUE)
  s1 <- sd(x[t == 1], na.rm = TRUE)
  s0 <- sd(x[t == 0], na.rm = TRUE)
  (m1 - m0) / sqrt((s1^2 + s0^2) / 2)
}

smd_video_duration  <- smd(random_merged$video_duration, random_merged$T)
smd_friend_user_num <- smd(random_merged$friend_user_num, random_merged$T)
smd_register_days   <- smd(random_merged$register_days, random_merged$T)

smd_video_duration
smd_friend_user_num
smd_register_days
```

Discovery: horizontal videos tend to be longer as well

```{r}
ggplot(random_merged, aes(x = factor(T), y = video_duration)) +
  geom_boxplot()
```

#### Diff-in-mean Estimate of treatment effect on click & like

```{r}
# diff_click <- random_merged %>%
#   summarise(
#     mean_treated  = mean(is_click[T == 1], na.rm = TRUE),
#     mean_control  = mean(is_click[T == 0], na.rm = TRUE),
#     diff_in_means = mean_treated - mean_control
#   )
# diff_like <- random_merged %>%
#   summarise(
#     mean_treated  = mean(is_like[T == 1], na.rm = TRUE),
#     mean_control  = mean(is_like[T == 0], na.rm = TRUE),
#     diff_in_means = mean_treated - mean_control
#   )
# 
# diff_table <- tibble(
#   outcome         = c("is_click", "is_like"),
#   mean_treated    = c(mean(random_merged$is_click[random_merged$T == 1]),
#                       mean(random_merged$is_like[random_merged$T == 1])),
#   mean_control    = c(mean(random_merged$is_click[random_merged$T == 0]),
#                       mean(random_merged$is_like[random_merged$T == 0])),
#   diff_in_means   = mean_treated - mean_control
# )
# diff_table
```

t-test insights:

```{r}
t.test(is_click ~ T, data = random_merged)
t.test(is_like  ~ T, data = random_merged)
```

Simple difference in mean estimator has shown that video being horizontal has a significant negative effect on the video click through rate, but a positive, insignificant effect on video like rate

The data scarcity for the number of likes received can be a factor for our reduced power in analyzing: overall we only have 0.55% of total video impressions in randomized trials that result in likes, compared to 17.4% click throughs

```{r}
mean(random_merged$is_click, na.rm = TRUE)
mean(random_merged$is_like,  na.rm = TRUE)
```

#### Lin's Estimator: Controlling for Covariates

Lists of covariates that we controlled:

-   number of users that this user follow

-   number of fans of this user

-   number of registered daysw

-   video duratioon

-   user active degree (full_active, high_active, mid_active, unknown)

-   whether the user has uploaded any video (binary)

-   whether this video is ads (binary)

```{r}
#covariates to be controlled for req: fixed before randomization, cannot be affected by treatment
#user_active_degree, is_video_author, follow_user_num, fans_user_num, register_days, video_type, upload_type, video_duration

numerical_covariates <- c(
  "follow_user_num",
  "fans_user_num",
  "register_days",
  "video_duration"
)

categorical_covariates <- c(
  "user_active_degree",
  "is_video_author",
  "video_type"
)

all_covariates <- c(numerical_covariates, categorical_covariates)

#center covariates
centered <- random_merged %>%
  mutate(across(all_of(numerical_covariates), ~ .x - mean(.x, na.rm = TRUE)))
```

```{r}
#clicks estimate:
form_click <- as.formula(
  paste("is_click ~ T * (", paste(all_covariates, collapse = " + "), ")")
)

lin_click <- lm(form_click, data = centered)
summary(lin_click)$coefficients["T", ]
```

```{r}
#like estimate
form_like <- as.formula(
  paste("is_like ~ T * (", paste(all_covariates, collapse = " + "), ")")
)

lin_like <- lm(form_like, data = centered)
summary(lin_like)$coefficients["T", ]
```

After controlling for covariates and potential interaction effects, we can see that the previously identified negative relationship between horizontal video format and video click through rate vanishes: i.e. when adjusting for video duration, user features, video type, and treatmentâ€“covariate interactions, there is **no evidence** of a causal effect of horizontal format on click-through probability.

In terms of video likes, there is still no any significant relationship identified

## Randomized Trial - Using 27K Instead

Given data scarcity might be an issue, resorting to random trials in complete data

```{r}
random_27k_path = 'data/KuaiRand-27K/log_random_4_22_to_5_08_27k.csv'
user_features_27k_path = 'data/KuaiRand-27K/user_features_27k.csv'
video_features_27k_path = 'data/KuaiRand-27K/video_features_basic_27k.csv'

random_27k = read.csv(random_27k_path)
user_features_27k = read.csv(user_features_27k_path)
#this one is super large and takes quite a while (2.6G)
video_features_27k = read.csv(video_features_27k_path)
```

```{r}
random_27k_merged <- random_27k %>%
  left_join(video_features_27k, by = "video_id")

random_27k_merged <- random_27k_merged %>%
  left_join(user_features_27k, by = "user_id")

length(unique(random_27k_merged$video_id))
length(unique(random_27k_merged$user_id))
dim(random_27k_merged)

#release storage
rm(random_27k, user_features_27k, video_features_27k)
```

```{r}
random_27k_merged$T = as.integer(random_27k_merged$server_width > random_27k_merged$server_height)
```

#### Diff in Means for 27K

Actually the same trend as analysis for 1K dataset under simple sample mean:

-   significant negative relationship between horizontal & click through

-   no significant relationship between horizontal & likes

```{r}
t.test(is_click ~ T, data = random_27k_merged)
t.test(is_like  ~ T, data = random_27k_merged)
```

#### Lin's for 27K

Again, no significant relationship after adjusting for relevant covariates.

```{r}
#covariates to be controlled for req: fixed before randomization, cannot be affected by treatment
#user_active_degree, is_video_author, follow_user_num, fans_user_num, register_days, video_type, upload_type, video_duration

numerical_covariates <- c(
  "follow_user_num",
  "fans_user_num",
  "register_days",
  "video_duration"
)

categorical_covariates <- c(
  "user_active_degree",
  "is_video_author",
  "video_type"
)

all_covariates <- c(numerical_covariates, categorical_covariates)

#center covariates
centered_27k <- random_27k_merged %>%
  mutate(across(all_of(numerical_covariates), ~ .x - mean(.x, na.rm = TRUE)))
```

```{r}
#clicks estimate:
form_click <- as.formula(
  paste("is_click ~ T * (", paste(all_covariates, collapse = " + "), ")")
)

lin_click <- lm(form_click, data = centered_27k)
summary(lin_click)$coefficients["T", ]
```

```{r}
#like estimate
form_like <- as.formula(
  paste("is_like ~ T * (", paste(all_covariates, collapse = " + "), ")")
)

lin_like <- lm(form_like, data = centered_27k)
summary(lin_like)$coefficients["T", ]
```

## Observational Studies

Next we try to see if we can recover the same relationship from observational data: i.e. when the videos are not randomized and are shown to users via Kuaishou's internal recommendation algorithm

#### Exploration & Comparison to randomized trials

standard have significantly more video impression logs than random

```{r}
standard_path = 'data/KuaiRand-1K/data/log_standard_4_22_to_5_08_1k.csv'
standard <- read.csv(standard_path)
```

```{r}
standard_merged <- standard %>%
  left_join(video_features, by = "video_id")

standard_merged <- standard_merged %>%
  left_join(user_features, by = "user_id")

length(unique(standard_merged$video_id))
length(unique(standard_merged$user_id))
dim(standard_merged)
```

Comparison table shows two datasets are very different

```{r}
summary_stats <- function(df, name) {
  data.frame(
    dataset = name,
    n_obs = nrow(df),
    prop_T1 = mean(df$T, na.rm = TRUE),
    click_rate = mean(df$is_click, na.rm = TRUE),
    like_rate = mean(df$is_like, na.rm = TRUE)
  )
}

random_27k_stats  <- summary_stats(random_27k_merged,  "Randomized Logs (27k)")
standard_stats <- summary_stats(standard_merged, "Recommendation Logs")

comparison_table <- bind_rows(random_27k_stats, standard_stats)
comparison_table
```

#### naive diff in mean

Naive diff in mean estimators directly applied on observational user-video interaction logs show biased results: for both click through and like ratio, horizontal format seems to have a positive efffect

```{r}
t.test(is_click ~ T, data = standard_merged)
t.test(is_like ~ T, data = standard_merged)
```

#### Propensity Score Model

```{r}
#double check the covariates we are controlling for
print(all_covariates)
```

```{r}
### build propensity score model
# Keep only rows with no NA in T or any covariate
standard_cc <- standard_merged %>%
  drop_na(T, all_of(all_covariates))

nrow(standard_merged)
nrow(standard_cc)  
```

```{r}
# Refit PS model on complete-case data
ps_model <- glm(ps_formula, data = standard_cc, family = binomial())

# Now this works: lengths match
standard_cc$ps <- predict(ps_model, type = "response")
```

Quite some overlap between propensity scores in treatment vs control

```{r}
ggplot(standard_cc, aes(x = ps, fill = factor(T))) +
  geom_density(alpha = 0.4) +
  labs(
    title = "Propensity Score Distribution by Treatment Group",
    x = "Propensity Score (P(T=1 | X))",
    fill = "Treatment"
  ) +
  scale_fill_manual(values = c("0" = "skyblue", "1" = "orange"),
                    labels = c("Vertical (T=0)", "Horizontal (T=1)")) +
  theme_minimal()

```

#### IPW

```{r}
#trim extreme weights
standard_ipw <- standard_cc %>%
  filter(ps > 0.02, ps < 0.98)

p_treated <- mean(standard_ipw$T == 1)

#calc inverse weights
standard_ipw <- standard_ipw %>%
  mutate(
    w_ATE = ifelse(
      T == 1,
      p_treated / ps,
      (1 - p_treated) / (1 - ps)
    )
  )

summary(standard_ipw$w_ATE)
quantile(standard_ipw$w_ATE, probs = c(0, 0.5, 0.9, 0.99, 1))
```

```{r}
## Checking covariates balance after reweighting
#this one takes a long time

bal.tab(
  x = standard_ipw %>% select(all_of(all_covariates)),
  treat = standard_ipw$T,
  weights = standard_ipw$w_ATE,
  estimand = "ATE"
)

love.plot(
  bal.tab(
    x = standard_ipw %>% select(all_of(all_covariates)),
    treat = standard_ipw$T,
    weights = standard_ipw$w_ATE,
    estimand = "ATE"
  ),
  threshold = 0.1
)

```

```{r}
#weighted regressions that give point estimates, SEs and p-values

ipw_click_lm <- lm(is_click ~ T, data = standard_ipw, weights = w_ATE)
coef(summary(ipw_click_lm))["T", ]

ipw_like_lm <- lm(is_like ~ T, data = standard_ipw, weights = w_ATE)
coef(summary(ipw_like_lm))["T", ]

```

```{r}
summary(standard_ipw$w_ATE)
quantile(standard_ipw$w_ATE, probs = c(0.9, 0.95, 0.99, 0.999, 1))

```

## Operational/Business Insights

Content creators might be less willing to create videos in horizontal format due to their perceived lower traffic (i.e click through rate). Our study essentially shows that the format of the video plays no significant role in influencing user's interaction and engagement of the videos when controlling for video-content and user features. Therefore, we encourage creators to choose simply the most suitable format for any particular video and prioritize the content quality instead.
